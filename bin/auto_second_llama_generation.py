from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate
from langchain_groq import ChatGroq
from typing import List
from langchain_core.pydantic_v1 import BaseModel, Field
import time
import json
import os
import pandas as pd
import logging
from tqdm import tqdm
import traceback
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)
logging.basicConfig(filename='second_llama_generation.log', level=logging.INFO)


class ObjectsDetected(BaseModel):
    objects_detected: List[str] = Field(description="List of detected objects")


llm = ChatGroq(model="llama3-70b-8192", temperature=0.5)
template = '''
You are an advanced language model tasked with merging detailed captions generated by two multimodal systems. Your goal is to create a unified, highly detailed, and factually accurate description of the image.  

Below is a detailed description of an image. Your task is to extract and list every object mentioned in the description that can be reliably detected by an object detection model. Please follow these instructions carefully:  

### Instructions:  
1. Identify each object that is clearly described and can be recognized by typical object detection systems.  
2. Be very cautious with numerical details attached to the objects, don't avoid them.  
3. Do not combine or generalize objects if different numbers are specified. Each unique instance should be explicitly listed.  
'''
system_message = SystemMessagePromptTemplate.from_template(template)
human_message = HumanMessagePromptTemplate.from_template("Here is description: {description}")

prompt_object_detection = ChatPromptTemplate.from_messages([system_message, human_message])
model = prompt_object_detection | llm.with_structured_output(ObjectsDetected)


request_counter = 0
last_reset_time = time.time()


def invoke_with_rate_limit_per_minute(description, requests_per_minute=29):
    global request_counter, last_reset_time

    current_time = time.time()
    if current_time - last_reset_time >= 60:
        request_counter = 0
        last_reset_time = current_time

    if request_counter >= requests_per_minute:
        wait_time = 60 - (current_time - last_reset_time)
        print(f"Rate limit reached. Please wait {wait_time:.2f} seconds.")
        time.sleep(wait_time)
        request_counter = 0
        last_reset_time = time.time()

    # Now make the request
    response = model.invoke({"description": description}).objects_detected

    # Increment the request counter after the request
    request_counter += 1

    return response


root = r"C:\Users\Gram\Desktop\NULP\uav_img_cap"

path_to_first_llama = os.path.join(root, "bin/inference_llama_first_80b.json")
path_to_second_llama = os.path.join(root, "bin/inference_llama_second_70b.json")


if not os.path.exists(path_to_second_llama):
    with open(path_to_second_llama, "w") as f:
        json.dump([], f)

with open(path_to_first_llama, "r") as f:
    first_llama_inference = json.loads(f.read())

with open(path_to_second_llama, "r") as f:
    second_llama_inference = json.loads(f.read())

first_llama_df = pd.DataFrame(first_llama_inference)

second_llama_df = pd.DataFrame(second_llama_inference)
checked_images = [] if len(second_llama_df) == 0 else second_llama_df.image.unique().tolist()
logger.info(f"amount of generated descriptions {len(checked_images)}")

logger.info("started generating descriptions")
for i, r in tqdm(first_llama_df[~first_llama_df.image.isin(checked_images)].iterrows(),
                 total=(~first_llama_df.image.isin(checked_images)).sum()):
    try:
        second_llama_inference.append({"image": r["image"],
                                      "objects": invoke_with_rate_limit_per_minute(r["description"])})
    except Exception as e:
        logger.info(f"got exception {traceback.format_exc()}")
        raise e
    finally:
        with open("inference_llama_second_70b.json", "w") as f:
            json.dump(second_llama_inference, f, indent=4)
        logger.info(f"finished with {len(second_llama_inference)} data points processed")
