{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07c7672f-2e7c-4a46-b24c-2d28ac7dc3ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c23a4848-85a6-4f11-946d-2220846d0d7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "940200a9-3e3b-48f4-87be-8bcccb38fd4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install langchain-groq\n",
    "import os\n",
    "\n",
    "# os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fc26ae9-7ad2-43e2-9f3c-5bb0b187198f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain.tools import tool\n",
    "# from langchain_core.messages import HumanMessage\n",
    "# from langgraph.checkpoint.memory import MemorySaver\n",
    "# from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a672288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "import time\n",
    "\n",
    "\n",
    "class ObjectsDetected(BaseModel):\n",
    "    objects_detected: List[str] = Field(description=\"List of detected objects\")\n",
    "\n",
    "        \n",
    "llm = ChatGroq(model=\"llama3-70b-8192\", temperature=0.5)\n",
    "template = '''\n",
    "You are an advanced language model tasked with merging detailed captions generated by two multimodal systems. Your goal is to create a unified, highly detailed, and factually accurate description of the image.  \n",
    "\n",
    "Below is a detailed description of an image. Your task is to extract and list every object mentioned in the description that can be reliably detected by an object detection model. Please follow these instructions carefully:  \n",
    "\n",
    "### Instructions:  \n",
    "1. Identify each object that is clearly described and can be recognized by typical object detection systems.  \n",
    "2. Be very cautious with numerical details attached to the objects, don't avoid them.  \n",
    "3. Do not combine or generalize objects if different numbers are specified. Each unique instance should be explicitly listed.  \n",
    "'''\n",
    "system_message = SystemMessagePromptTemplate.from_template(template)\n",
    "human_message = HumanMessagePromptTemplate.from_template(\"Here is description: {description}\")\n",
    "\n",
    "prompt_object_detection = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "model = prompt_object_detection | llm.with_structured_output(ObjectsDetected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f727cac6-98d6-4805-ae68-6eb3109cbe54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'car', 'car', 'route']\n"
     ]
    }
   ],
   "source": [
    "request_counter = 0\n",
    "last_reset_time = time.time()\n",
    "\n",
    "\n",
    "def invoke_with_rate_limit_per_minute(description, requests_per_minute = 29):\n",
    "    global request_counter, last_reset_time\n",
    "\n",
    "    current_time = time.time()\n",
    "    if current_time - last_reset_time >= 60:\n",
    "        request_counter = 0\n",
    "        last_reset_time = current_time\n",
    "\n",
    "    if request_counter >= requests_per_minute:\n",
    "        wait_time = time_window - (current_time - last_reset_time)\n",
    "        print(f\"Rate limit reached. Please wait {wait_time:.2f} seconds.\")\n",
    "        time.sleep(wait_time)  # Sleep until the next allowed time\n",
    "        request_counter = 0  # Reset the counter after waiting\n",
    "        last_reset_time = time.time()\n",
    "\n",
    "    # Now make the request\n",
    "    response = model.invoke({\"description\": description}).objects_detected\n",
    "\n",
    "    # Increment the request counter after the request\n",
    "    request_counter += 1\n",
    "\n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "result = invoke_with_rate_limit_per_minute(\"there are 3 cars are driving on dirty route\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb6a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: regenerate first_llama_responses with groq 80b llama"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uav_img_cap",
   "language": "python",
   "name": "uav_img_cap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}